\pagenumbering{arabic}
\setcounter{page}{1}
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section*{Background and rationale}
\addcontentsline{toc}{section}{Background and rationale}

Data-driven society of today means that companies rely more and more on insights from data sets to make wise choices, optimize procedures, and keep one step ahead of the competition. The need of data engineers in building and overseeing the physical infrastructure and data pipelines has grown exponentially with the amount of data.

In this sense, building data pipelines has come to be a paradigm for functional programming. Because it is so adaptable and works well with the Java environment, Scala, a programming language that blends object-oriented and functional programming concepts, has drawn interest in the data engineering domain.

The choice to concentrate on this subject comes from the growing importance of data engineering in the big data age and the need for data engineers to adopt methods and technologies that make it possible to build scalable pipelines. Within Scala, functional programming offers a solution to the problems data engineers have when effectively processing huge datasets.

This work is both theoretical and empirical as it shows how to use Scala's functional programming to efficiently design data while also providing a theoretical discourse. My master's thesis subject was further motivated by the way theory and practice were integrated.

\section*{Research objectives}
\addcontentsline{toc}{section}{Research objectives and learning goals}

The primary goal of this thesis is to investigate the use of programing, in Scala, for creating scalable and maintainable data pipelines. Emphasizing understanding the principles and techniques. The research was driven by a desire to gain practical knowledge and skills in data engineering using Scala.

\section*{Purpose and scope of the study}
\addcontentsline{toc}{section}{Purpose and scope}

The goal of this thesis is to investigate the use of programing, in Scala, for constructing scalable data pipelines. The study examines the principles, libraries, and frameworks within the Scala ecosystem that are relevant to data engineering.

The scope of the work covers the data engineering workflow, from data acquisition and storage to, processing, delivery, and monitoring. In addition, it considers employing the Scala for both batch and streaming data pipelines, deliberating on the advantages and best practices associated with each method.

\section*{Research methods}
\addcontentsline{toc}{section}{Research methods}

 This thesis employs a combination of theoretical analysis and practical exploration to investigate the use of functional programming in Scala for data engineering. An extensive \textbf{literature review} on functional programming concepts, Scala language features, and data engineering principles was conducted to establish the theoretical foundation. Key concepts in functional programming and data engineering were analyzed and synthesized to understand their applicability and benefits in building data pipelines. Practical code examples in Scala were developed and presented throughout the thesis to illustrate how functional programming concepts can be applied to data engineering tasks. Different approaches, frameworks, and libraries within the Scala ecosystem for data processing were examined and compared to evaluate their strengths and use cases.  Hypothetical scenarios and real-world inspired examples were used to demonstrate the application of Scala and functional programming principles to data engineering problems. Various data pipeline architectures and processing paradigms were analyzed to understand how functional programming in Scala can be leveraged in different contexts.

\section*{Thesis structure}
\addcontentsline{toc}{section}{Thesis structure}

Chapter 1 "Core Principles of Functional Programming in Scala for Data Engineering" explores how Scala, can be leveraged for data engineering. It covers:

\begin{itemize}
    \item Background on Scala's development and design philosophy;
    \item Core features of functional programming in Scala:
\begin{itemize}
    \item Immutable data structures,
    \item Higher-order functions,
    \item Lazy evaluation,
    \item Pattern matching and algebraic data types,
    \item Type classes,
    \item Monads and error handling,
    \item Parallel and distributed processing capabilities;
\end{itemize}
\item The chapter provides code examples to illustrate how these concepts can be applied to data engineering scenarios.

\end{itemize}

Chapter 2 "Data Engineering Workflow" provides a detailed overview of the data engineering workflow, covering:

\begin{itemize}
    \item Data quality dimensions (accuracy, completeness, consistency, timeliness, uniqueness),
    \item Data ingestion processes,
    \item Data processing techniques,
    \item Data storage systems (data warehouses, data lakes, NoSQL databases),
    \item Data integration and pipeline architectures (ETL vs ELT),
    \item Data security and governance,
    \item Data serving,
    \item Monitoring and maintenance of data pipelines.
\end{itemize}

Chapter 3 "Parallel and Distributed Data Processing" explores how Scala's features can be utilized for efficient parallel and distributed data processing; Focuses on techniques for processing large-scale data, including:

\begin{itemize}
    \item Fundamentals of parallel and distributed processing for big data,
    \item Distributed processing frameworks (e.g., Apache Hadoop, Apache Spark),
    \item Architectural patterns for big data processing (e.g., Lambda and Kappa architectures),
    \item Parallel collections in Scala,
    \item Futures and asynchronous programming,
    \item The Akka framework and actor model,
    \item Apache Spark's DataFrames and APIs.
\end{itemize}

Chapter 4 "Stream Processing with Scala" discusses how stream processing fits into the broader data engineering landscape and its implementation using Scala-based tools; Covers stream processing concepts and their implementation in Scala:

\begin{itemize}
    \item Core concepts of stream processing,
    \item Evolution of data processing paradigms,
    \item Stream processing in modern data engineering and big data ecosystems,
    \item Challenges and considerations in stream processing,
    \item Stream processing technologies and frameworks,,
    \item Popular stream processing frameworks in Scala (e.g., Apache Spark Structured Streaming, Akka Streams).
\end{itemize}

Chapter 5 "Testing Data Pipelines" emphasizes the importance of comprehensive testing in ensuring reliable and efficient data processing systems; Focuses on testing methodologies for data pipelines: 

\begin{itemize}
    \item Testing levels for data pipelines (unit, integration, end-to-end);
    \item Testing frameworks and tools specific to Scala;
    \item Approaches for testing data quality, performance, and scalability;
    \item Challenges in testing data pipelines and strategies to address them.
\end{itemize}

Chapter 6 "Deploying and Monitoring Data Pipelines" discusses best practices for maintaining and optimizing data pipelines in production environments; Covers the operational aspects of data pipelines: 

\begin{itemize}
    \item Deployment strategies, including cloud deployment;
    \item Monitoring techniques and tools for data pipelines;
    \item Performance optimization and troubleshooting;
    \item Scaling considerations for data pipelines;
    \item Continuous integration and deployment (CI/CD) for data engineering projects.
\end{itemize}