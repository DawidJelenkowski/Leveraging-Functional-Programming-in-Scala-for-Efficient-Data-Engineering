\pagenumbering{arabic}
\setcounter{page}{1}
\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section*{Background and rationale}
\addcontentsline{toc}{section}{Background and rationale}

In today's world driven by data, organizations are increasingly depended on insights gathered from data sets to make informed decisions, streamline processes and stay ahead of the competition. With the exponent growth of data, the role of data engineers has become essential in creating and managing both the psychical infrastructure and data pipelines.

In this context, functional programming has emerged as a paradigm, for constructing data pipelines. Scala, a programming language that seamlessly combines both object-oriented and functional programming principles, has garnered attention in the data engineering field for its versatility and compatibility with the Java ecosystem.

The decision to focus on this topic arises from the rising significance of data engineering in the big data era and the necessity for data engineers to embrace tools and techniques that enable them to construct scalable pipelines. Functional programming, within Scala, presents a solution to tackle the challenges encountered by data engineers in efficiently processing large datasets.

The work is both theoretical and empirical, as it presents a theoretical discourse and demonstrates the practical application of leveraging functional programming in Scala for efficient data engineering. The integration of theory and practice served as an additional motivation for undertaking this topic for my master's thesis.

\section*{Research objectives}
\addcontentsline{toc}{section}{Research objectives and learning goals}

The primary goal of this thesis is to investigate the utilization of programming, in Scala, for creating scalable and maintainable data pipelines. The emphasis was placed on understanding the principles and techniques. The specific research objectives are:

\begin{enumerate}
    \item To explore the fundamental principles of functional programming in Scala and their application to data engineering.
    \item To examine the design and implementation of scalable, maintainable data pipelines using Scala and relevant libraries.
    \item To explore the best practices and design patterns for building data engineering workflows in Scala.
    \item To investigate the use of Scala for parallel and distributed data processing, using frameworks like Apache Spark.
    \item To explore the challenges and techniques for stream processing and real-time data analytics using Scala.
    \item To examine the testing, monitoring, and deployment strategies for Scala-based data pipelines in production environments.
\end{enumerate}

By focusing on these goals, the thesis aims to provide a comprehensive understanding of how functional programming in Scala can be applied to build robust and efficient data pipelines. The research was driven by a desire to gain practical knowledge and skills in data engineering using Scala.

\section*{Purpose and scope}
\addcontentsline{toc}{section}{Purpose and scope}

The goal of this thesis is to delve into the utilization of programming, in Scala, for constructing scalable data pipelines.

The research delves into examining the principles, libraries, and frameworks within the Scala ecosystem that're relevant to data engineering. It illustrates their implementation through real-world examples and case studies.

The scope of the work covers the data engineering workflow, from data acquisition and storage, to processing, delivery, and monitoring. Additionally, it delves into employing Scala for both batch and streaming data pipelines, deliberating on the advantages and best practices associated with each method.

\section*{Research methods}
\addcontentsline{toc}{section}{Research methods}

The research employs a combination of literature review, practical experimentation, and case study analysis. The literature review involves a comprehensive survey of existing research on functional programming, Scala, and data engineering, to establish a solid theoretical foundation for the work.

Practical experimentation involves hands-on development of data pipelines using Scala and relevant libraries, such as Akka, Cats, Fs2, and Monix. The experiments aim to validate the applicability of functional programming techniques to real-world data engineering scenarios and identify best practices and design patterns.

Case study analysis involves examining real-world examples of data pipelines built using Scala and functional programming, to derive insights into their architecture, performance, and maintainability. The case studies were selected based on their relevance to the research goals and their potential to provide valuable lessons for data engineers.

\section*{Thesis structure}
\addcontentsline{toc}{section}{Thesis structure}

The thesis is structured into seven chapters, each focusing on a specific aspect of leveraging functional programming in Scala for data engineering.

The first chapter lies the groundwork by introducing the key concepts and principles of functional programming in Scala and discussing their relevance to data engineering. This provides a solid foundation for the subsequent chapters.

The second chapter dives into the practical application of Scala and functional programming in building data pipelines. It explores the development of both batch and streaming pipelines, utilizing relevant libraries and frameworks. 

In the third chapter, the focuses shift to parallel and distributed data processing. It investigates how Scala's functional programming features can be harnessed to efficiently process large datasets using frameworks like Apache Spark and other distributed computing tools.

The fourth chapter delves into the realm of stream processing with Scala. It examines the use of libraries such as Akka Streams and Monix Observable for real-time data processing and discusses the challenges and best practices associated with building streaming data pipelines. Testing is a crucial aspect of any software development process, and data pipelines are no exception.

The fifth chapter explores how functional programming techniques can be applied to test data pipelines, using tools like ScalaCheck and Mockito. It emphasizes the importance of testing in ensuring the reliability and correctness of data engineering workflows.

The sixth chapter focuses on the deployment and monitoring of Scala-based data pipelines in production environments. It covers techniques and best practices for deployment using tools such as Docker and Kubernetes. Additionally, it highlights the significance of monitoring and logging in maintaining the health and performance of data pipelines.

Finally, the seventh chapter concludes the thesis by summarizing the key findings and contributions. It discusses the limitations of the research and potential avenues for future work. The chapter also provides recommendations for data engineers looking to leverage functional programming in Scala for building efficient data pipelines.